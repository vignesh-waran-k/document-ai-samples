{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49bf864f-c8d8-47c9-af54-b253f41bca88",
   "metadata": {},
   "source": [
    "# DocAI Special Character Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2388af64-6727-4876-b3ef-296cd321c302",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84b2797-4849-48ec-b222-09c150dcc4e0",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the DocAI Incubator Team. No guarantees of performance are implied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79756a4c-45b1-4507-9c8e-7b7c9e504170",
   "metadata": {},
   "source": [
    "## Purpose and Description\n",
    "\n",
    "This documentation outlines the procedure for handling special characters within the CDE JSON samples. It involves replacing the original mention text value with its corresponding post-processed value using the provided code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c3b23-a58e-4f9f-ad92-d3e05ba1a619",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Access to vertex AI Notebook or Google Colab\n",
    "2. Python\n",
    "3. Access to the google storage bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac4060-3e3c-43fc-a1ee-9feb9544373c",
   "metadata": {},
   "source": [
    "## Step by Step procedure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c96f566-cd19-444a-9b68-95d4d2d125ed",
   "metadata": {},
   "source": [
    "### 1. Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e13449-1ca7-4f1c-8a73-1cdbe4b74db6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (9.5.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for fastjsonschema: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/fastjsonschema-2.18.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.7/site-packages (2.11.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.28.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.17.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.6.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.60.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.20.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media>=2.6.0->google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.2.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.5.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for fastjsonschema: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/fastjsonschema-2.18.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: google-cloud-documentai in /opt/conda/lib/python3.7/site-packages (2.24.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-documentai) (2.17.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-documentai) (2.28.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-documentai) (1.22.3)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-documentai) (3.20.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-documentai) (1.60.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-documentai) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-documentai) (1.58.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-documentai) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-documentai) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-documentai) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-documentai) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-documentai) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-documentai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-documentai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-documentai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-documentai) (2024.2.2)\n",
      "\u001b[33mWARNING: Error parsing requirements for fastjsonschema: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/fastjsonschema-2.18.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install Pillow\n",
    "%pip install google-cloud-storage\n",
    "%pip install google-cloud-documentai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0b148e-2fc1-41ea-94e1-7e0681aa4c6c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-23 09:28:19--  https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29735 (29K) [text/plain]\n",
      "Saving to: ‘utilities.py’\n",
      "\n",
      "utilities.py        100%[===================>]  29.04K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2024-04-23 09:28:19 (17.9 MB/s) - ‘utilities.py’ saved [29735/29735]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79501f4-7df9-4ff3-9849-c0922718d939",
   "metadata": {},
   "source": [
    "### 2. Import the required libraries/Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f907df-4fe2-4ae8-9d1d-33cf77f764fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from google.cloud import storage\n",
    "from PIL import Image\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from pathlib import Path\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "from utilities import file_names,documentai_json_proto_downloader,store_document_as_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0057355b-8edb-4394-aed9-6cae90975184",
   "metadata": {},
   "source": [
    "### 3. Input Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7883f7-2912-4c8a-ab0a-31ad66b4e9cf",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>input_path : </b>It is input GCS folder path which contains DocumentAI processor JSON results</li>\n",
    "    <li><b>output_path : </b> It is a GCS folder path to store post-processing results</li>\n",
    "    <li><b>project_id : </b> It is the project id of the current project.</li>\n",
    "    <li><b>location : </b> It is the location of the project in the processor.</li>\n",
    "    <li><b>processor_id : </b> It is the cde processor id. </li>\n",
    "    <li><b>entity_name : </b> The name of an entity to consider for cleaning and converting it with post processed value.</li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9b0c0d7-31b7-4657-97f7-e6f21d5906f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'gs://venky_currency_normalization/Cheque1_json/' # gs://bucket_name/path/to/jsons/\n",
    "output_path = 'gs://venky_currency_normalization/Cheque1_json_output_1/' # gs://bucket_name/path/to/output\n",
    "project_id = \"rand-automl-project\" # \"project-id\" \n",
    "location = \"us\" # us  location\n",
    "processor_id = \"95ca748b79eeee4e\" # 95ca748b79eeee4e  processor-id\n",
    "entity_name = \"Amount_in_number\" # It is the entity name which need to be converted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4d367c-4ef3-46ae-ba0a-43bd2d9c7f6b",
   "metadata": {},
   "source": [
    "### 4.Execute the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39691d-db63-4f1f-9764-67d866933da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_storage_bucket_name = input_path.split('/')[2]\n",
    "input_bucket_path_prefix = '/'.join(input_path.split('/')[3:])\n",
    "output_storage_bucket_name=output_path.split('/')[2]   \n",
    "output_bucket_path_prefix = '/'.join(output_path.split('/')[3:])\n",
    "\n",
    "def remove_special_characters(json_proto_data: documentai.Document,  entity_name: str) -> documentai.Document:\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Removes special characters from a specified entity type (\"entity_name\") in a Documentai document.\n",
    "\n",
    "    This function processes the entity bounding box, extracts the image data, performs OCR with symbol confidence, \n",
    "    and removes special characters like '-' and '/' based on confidence thresholds while considering adjacent digits.\n",
    "\n",
    "    Args:\n",
    "      json_proto_data: The Documentai document object containing text and entities (type: documentai.Document).\n",
    "      entity_name: The name of the entity type to process (type: str).\n",
    "\n",
    "    Returns:\n",
    "      The modified Documentai document object with updated entity mentions after removing special characters (type: documentai.Document).\n",
    "    \"\"\"\n",
    "    for page_index, page in enumerate(json_proto_data.pages):\n",
    "        \n",
    "        if 'image' in page and 'content' in page.image:\n",
    "            # Decode the image content\n",
    "            image_data = page.image.content\n",
    "            #image_data = base64.b64decode(image_data_base64)\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "            for entity in json_proto_data.entities:\n",
    "                if entity.type == entity_name:\n",
    "                    bounding_box = entity.page_anchor.page_refs[0].bounding_poly.normalized_vertices\n",
    "\n",
    "                    # Convert normalized coordinates to pixel coordinates\n",
    "                    img_width, img_height = image.size\n",
    "                    left = bounding_box[0].x * img_width\n",
    "                    top = bounding_box[0].y * img_height\n",
    "                    right = bounding_box[2].x * img_width\n",
    "                    bottom = bounding_box[2].y * img_height\n",
    "\n",
    "                    # Crop the image\n",
    "                    cropped_image = image.crop((left, top, right, bottom))\n",
    "\n",
    "                    # Convert the PIL image to bytes directly\n",
    "                    cropped_image_bytes = BytesIO()\n",
    "                    cropped_image.save(cropped_image_bytes, format='PNG')\n",
    "                    image_content = cropped_image_bytes.getvalue()\n",
    "\n",
    "                    docai_client = documentai.DocumentProcessorServiceClient(client_options=ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\"))\n",
    "                    RESOURCE_NAME = docai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "                    raw_document = documentai.RawDocument(content=image_content, mime_type=\"image/png\")\n",
    "                    process_options = {\"ocr_config\": {\"enable_symbol\":True}}\n",
    "                    request = documentai.ProcessRequest(name=RESOURCE_NAME, raw_document=raw_document, process_options=process_options)\n",
    "\n",
    "                    result = docai_client.process_document(request=request)\n",
    "                    new_json_proto_data = result.document\n",
    "\n",
    "                    # Extracting text and confidence values\n",
    "                    # new_json_data = json.loads(documentai.Document.to_json(document_object))\n",
    "                    complete_text = new_json_proto_data.text\n",
    "                    symbols_confidence = []\n",
    "\n",
    "                    for page in new_json_proto_data.pages:\n",
    "                        for symbol in page.symbols:\n",
    "                            segments = symbol.layout.text_anchor.text_segments[0]\n",
    "                            start_index = int(segments.start_index)\n",
    "                            end_index = int(segments.end_index)\n",
    "                            symbol_text = complete_text[start_index:end_index]\n",
    "                            confidence = symbol.layout.confidence\n",
    "                            symbols_confidence.append((symbol_text, confidence))\n",
    "\n",
    "                    # Initially filter out '-' and '/' without affecting adjacent numeric values\n",
    "                    symbols_confidence_filtered = [(sym, conf) for sym, conf in symbols_confidence if sym not in ('-', '/')]\n",
    "\n",
    "                    # Check and remove the first symbol if its confidence is below 0.85\n",
    "                    if symbols_confidence_filtered and symbols_confidence_filtered[0][1] < 0.85:\n",
    "                        symbols_confidence_filtered.pop(0)\n",
    "\n",
    "                    # Check and remove the last two symbols if their confidences are below 0.85\n",
    "                    if len(symbols_confidence_filtered) > 2 and symbols_confidence_filtered[-1][1] < 0.85:\n",
    "                        symbols_confidence_filtered.pop(-1)\n",
    "                    if len(symbols_confidence_filtered) > 2 and symbols_confidence_filtered[-2][1] < 0.85:\n",
    "                        symbols_confidence_filtered.pop(-2)\n",
    "\n",
    "                    if len(symbols_confidence_filtered) > 2:\n",
    "                        for j in range(1,len(symbols_confidence_filtered)-2):\n",
    "                            if symbols_confidence_filtered[j][1] < 0.5:\n",
    "                                symbols_confidence_filtered.pop(j)\n",
    "\n",
    "                    # Join the remaining characters from the processed list\n",
    "                    post_processed_symbols = ''.join([sym for sym, conf in symbols_confidence_filtered])\n",
    "                    entity.mention_text = post_processed_symbols\n",
    "            return json_proto_data\n",
    "                \n",
    "                \n",
    "                \n",
    "list_of_files = [i for i in  list(file_names(input_path)[1].values()) if i.endswith(\".json\")]\n",
    " \n",
    "for i in range(0,len(list_of_files)):\n",
    "    file_name = list_of_files[i]\n",
    "    #json_data=json.loads(source_bucket.blob(list_of_files[i]).download_as_string().decode('utf-8'))\n",
    "    json_proto_data = documentai_json_proto_downloader(input_storage_bucket_name, file_name)\n",
    "    print(\"Processing>>>>>>>\",file_name)\n",
    "    document_proto = remove_special_characters(json_proto_data,entity_name)\n",
    "    output_path_within_bucket = output_bucket_path_prefix + file_name.split('/')[1]\n",
    "    store_document_as_json(documentai.Document.to_json(document_proto), output_storage_bucket_name, output_path_within_bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91819249-1209-4a61-8376-32ad56f2ca8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
